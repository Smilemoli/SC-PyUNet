import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import random

class IronSpectrumDataset(Dataset):
    def __init__(self, img_dir, mask_dir, img_size=512, is_train=True, indices=None):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.img_size = img_size
        self.is_train = is_train

        all_images = sorted([f for f in os.listdir(img_dir) if f.endswith('.png')])
        all_masks = sorted([f for f in os.listdir(mask_dir) if f.endswith('.png')])

        if indices is not None:
            self.images = [all_images[i] for i in indices]
            self.masks = [all_masks[i] for i in indices]
        else:
            self.images = all_images
            self.masks = all_masks

        # å›¾åƒé¢„å¤„ç†å’Œå½’ä¸€åŒ–
        self.image_transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

        # æ ‡ç­¾é¢„å¤„ç†
        self.mask_transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor()
        ])

        # æ•°æ®å¢å¼º
        self.augmentation = transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2)
        ]) if is_train else None

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.images[idx])
        mask_path = os.path.join(self.mask_dir, self.masks[idx])

        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')

        # åº”ç”¨æ•°æ®å¢å¼º
        if self.is_train and self.augmentation:
            seed = torch.randint(0, 2**32, (1,)).item()
            torch.manual_seed(seed)
            image = self.augmentation(image)
            torch.manual_seed(seed)
            mask = self.augmentation(mask)

        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–
        image = self.image_transform(image)
        mask = self.mask_transform(mask)

        # ç¡®ä¿æ ‡ç­¾ä¸ºäºŒå€¼
        mask = (mask > 0.5).float()

        return {
            'image': image,
            'mask': mask,
            'filename': self.images[idx]
        }

class MixedDataset(Dataset):
    """æ··åˆçœŸå®æ•°æ®å’Œå¢å¼ºæ•°æ®çš„æ•°æ®é›†"""
    def __init__(self, real_dataset, aug_dataset, real_ratio=0.75):
        """
        Args:
            real_dataset: çœŸå®æ•°æ®é›†
            aug_dataset: å¢å¼ºæ•°æ®é›†  
            real_ratio: çœŸå®æ•°æ®åœ¨æ··åˆä¸­çš„æ¯”ä¾‹ (0.0-1.0)
        """
        self.real_dataset = real_dataset
        self.aug_dataset = aug_dataset
        self.real_ratio = real_ratio
        
        # è®¡ç®—æ€»é•¿åº¦ï¼Œç¡®ä¿æ¯ä¸ªepochéƒ½èƒ½éå†åˆ°æ‰€æœ‰çœŸå®æ•°æ®
        self.total_length = max(len(real_dataset), int(len(real_dataset) / real_ratio))
        
    def __len__(self):
        return self.total_length
    
    def __getitem__(self, idx):
        # æ ¹æ®æ¯”ä¾‹å†³å®šé‡‡æ ·æ¥æº
        if random.random() < self.real_ratio:
            # é‡‡æ ·çœŸå®æ•°æ®
            real_idx = idx % len(self.real_dataset)
            return self.real_dataset[real_idx]
        else:
            # é‡‡æ ·å¢å¼ºæ•°æ®
            aug_idx = random.randint(0, len(self.aug_dataset) - 1)
            return self.aug_dataset[aug_idx]

def create_mixed_dataloaders(real_img_dir, real_mask_dir, aug_img_dir=None, aug_mask_dir=None, 
                            batch_size=16, img_size=224, num_workers=4, real_ratio=0.75):
    """
    åˆ›å»ºæ··åˆè®­ç»ƒæ•°æ®åŠ è½½å™¨å’Œçº¯å‡€éªŒè¯æ•°æ®åŠ è½½å™¨
    
    Args:
        real_img_dir: çœŸå®å›¾åƒç›®å½•
        real_mask_dir: çœŸå®æ ‡ç­¾ç›®å½•
        aug_img_dir: å¢å¼ºå›¾åƒç›®å½• (å¯é€‰)
        aug_mask_dir: å¢å¼ºæ ‡ç­¾ç›®å½• (å¯é€‰)
        batch_size: æ‰¹æ¬¡å¤§å°
        img_size: å›¾åƒå°ºå¯¸
        num_workers: å·¥ä½œçº¿ç¨‹æ•°
        real_ratio: çœŸå®æ•°æ®åœ¨è®­ç»ƒæ‰¹æ¬¡ä¸­çš„æ¯”ä¾‹
    """
    
    # Step 1: åˆ’åˆ†çœŸå®æ•°æ®ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
    all_real_images = sorted([f for f in os.listdir(real_img_dir) if f.endswith('.png')])
    np.random.seed(42)
    train_idx = np.random.choice(
        len(all_real_images), int(0.8 * len(all_real_images)), replace=False
    )
    val_idx = np.array(list(set(range(len(all_real_images))) - set(train_idx)))

    # Step 2: åˆ›å»ºçœŸå®æ•°æ®çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†
    real_train_dataset = IronSpectrumDataset(
        img_dir=real_img_dir, mask_dir=real_mask_dir, 
        img_size=img_size, is_train=True, indices=train_idx
    )
    
    # éªŒè¯é›†åªä½¿ç”¨çœŸå®æ•°æ®ï¼Œä¸ä½¿ç”¨å¢å¼º
    val_dataset = IronSpectrumDataset(
        img_dir=real_img_dir, mask_dir=real_mask_dir, 
        img_size=img_size, is_train=False, indices=val_idx
    )

    # Step 3: æ ¹æ®æ˜¯å¦æä¾›å¢å¼ºæ•°æ®è·¯å¾„ï¼Œå†³å®šè®­ç»ƒç­–ç•¥
    if aug_img_dir and aug_mask_dir and os.path.exists(aug_img_dir) and os.path.exists(aug_mask_dir):
        print("ğŸ”¥ æ£€æµ‹åˆ°å¢å¼ºæ•°æ®ï¼Œå¯ç”¨æ··åˆè®­ç»ƒç­–ç•¥ï¼")
        
        # åˆ›å»ºå¢å¼ºæ•°æ®é›†
        aug_dataset = IronSpectrumDataset(
            img_dir=aug_img_dir, mask_dir=aug_mask_dir,
            img_size=img_size, is_train=True, indices=None  # ä½¿ç”¨æ‰€æœ‰å¢å¼ºæ•°æ®
        )
        
        # åˆ›å»ºæ··åˆæ•°æ®é›†
        mixed_train_dataset = MixedDataset(
            real_dataset=real_train_dataset,
            aug_dataset=aug_dataset,
            real_ratio=real_ratio
        )
        
        print(f"ğŸ“Š è®­ç»ƒé›†æ„æˆ:")
        print(f"   - çœŸå®è®­ç»ƒæ•°æ®: {len(real_train_dataset)} å¼ ")
        print(f"   - å¢å¼ºæ•°æ®: {len(aug_dataset)} å¼ ") 
        print(f"   - æ··åˆæ¯”ä¾‹: {real_ratio:.1%} çœŸå®æ•°æ® + {1-real_ratio:.1%} å¢å¼ºæ•°æ®")
        print(f"   - æ¯ä¸ªæ‰¹æ¬¡æœŸæœ›æ„æˆ: {int(batch_size * real_ratio)} å¼ çœŸå® + {batch_size - int(batch_size * real_ratio)} å¼ å¢å¼º")
        
        train_dataset = mixed_train_dataset
    else:
        print("ğŸ“ æœªæ£€æµ‹åˆ°å¢å¼ºæ•°æ®ï¼Œä½¿ç”¨çº¯çœŸå®æ•°æ®è®­ç»ƒ")
        train_dataset = real_train_dataset

    # Step 4: åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )

    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ:")
    print(f"   - è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"   - éªŒè¯é›†å¤§å°: {len(val_dataset)} (çº¯çœŸå®æ•°æ®)")
    
    return train_loader, val_loader

# ä¿æŒå‘åå…¼å®¹æ€§
def create_dataloaders(img_dir, mask_dir, batch_size=16, img_size=224, num_workers=4):
    """åŸæœ‰çš„æ•°æ®åŠ è½½å™¨åˆ›å»ºå‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹æ€§"""
    return create_mixed_dataloaders(
        real_img_dir=img_dir,
        real_mask_dir=mask_dir,
        batch_size=batch_size,
        img_size=img_size,
        num_workers=num_workers
    )